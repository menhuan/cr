from typing import Dict, Any, List
import textwrap
from typing import Dict, Any, List
import re
import json
from urllib.parse import urlparse
import gitlab
from gitlab.v4.objects import Project, ProjectMergeRequest, ProjectNote
from dotenv import load_dotenv
import os
from src.logger import logger  # ç›´æ¥å¯¼å…¥é…ç½®å¥½çš„ logger
from typing import Dict, List, Any
from .java_analyzer import JavaCodeAnalyzer
from time import sleep

def pretty_print_json(data: Dict[str, Any], title: str = None) -> None:
    """
    ç¾åŒ–è¾“å‡º JSON æ•°æ®
    
    Args:
        data: è¦è¾“å‡ºçš„æ•°æ®å­—å…¸
        title: è¾“å‡ºçš„æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰
    """
    if title:
        logger.info(f"\n{title}:")
    logger.info(json.dumps(data, indent=2, ensure_ascii=False))



class GitLabMRParser:
    def __init__(self, gitlab_token: str, gitlab_url: str = "https://gitlab.com"):
        """åˆå§‹åŒ–"""
        self.gl = gitlab.Gitlab(url=gitlab_url, private_token=gitlab_token)
        self.java_analyzer = JavaCodeAnalyzer()  # åˆå§‹åŒ–Javaåˆ†æå™¨
        self.ai_reviewer = AICodeReviewer()
    def parse_mr_url(self, url: str) -> Dict[str, str]:
        """
        è§£æ GitLab MR URL
        
        Args:
            url: GitLab MR URL å¦‚ https://gitlab.com/group/project/-/merge_requests/1
            
        Returns:
            åŒ…å«è§£æç»“æœçš„å­—å…¸
        """
        logger.debug(f"Parsing MR URL: {url}")
        parsed = urlparse(url)
        pattern = r'/([^/]+)/([^/]+)/-/merge_requests/(\d+)'
        match = re.search(pattern, parsed.path)
        
        if not match:
            error_msg = f"Invalid GitLab MR URL format: {url}"
            logger.error(error_msg)
            raise ValueError(error_msg)
            
        namespace, project_name, mr_iid = match.groups()
        project_id = f"{namespace}/{project_name}"
        
        result = {
            'base_url': f"{parsed.scheme}://{parsed.netloc}",
            'namespace': namespace,
            'project_name': project_name,
            'project_id': project_id,
            'mr_iid': int(mr_iid)
        }
        logger.debug(f"Parsed MR URL result: {result}")
        return result

    def get_project(self, project_id: str) -> Project:
        """
        è·å– GitLab é¡¹ç›®å¯¹è±¡
        
        Args:
            project_id: é¡¹ç›®IDæˆ–è·¯å¾„ï¼ˆå¦‚ 'group/project'ï¼‰
            
        Returns:
            Project å¯¹è±¡
        """
        logger.info(f"Getting project: {project_id}")
        try:
            project = self.gl.projects.get(project_id)
            logger.debug(f"Successfully got project: {project.name}")
            return project
        except gitlab.exceptions.GitlabError as e:
            error_msg = f"Failed to get project {project_id}: {str(e)}"
            logger.error(error_msg)
            raise

    def get_merge_request(self, project: Project, mr_iid: int) -> ProjectMergeRequest:
        """
        è·å–åˆå¹¶è¯·æ±‚å¯¹è±¡
        
        Args:
            project: Project å¯¹è±¡
            mr_iid: MR IID
            
        Returns:
            ProjectMergeRequest å¯¹è±¡
        """
        logger.info(f"Getting merge request: {mr_iid} from project: {project.name}")
        try:
            mr = project.mergerequests.get(mr_iid)
            logger.debug(f"Successfully got MR: {mr.title}")
            return mr
        except gitlab.exceptions.GitlabError as e:
            error_msg = f"Failed to get MR {mr_iid}: {str(e)}"
            logger.error(error_msg)
            raise

    def get_mr_changes(self, url: str) -> Dict[str, Any]:
        """
        è·å– MR çš„å˜æ›´å†…å®¹
        
        Args:
            url: GitLab MR URL
            
        Returns:
            åŒ…å«å˜æ›´å†…å®¹çš„å­—å…¸
        """
        logger.info(f"Getting MR changes for: {url}")
        try:
            parsed_info = self.parse_mr_url(url)
            project = self.get_project(parsed_info['project_id'])
            mr = self.get_merge_request(project, parsed_info['mr_iid'])
            
            changes = mr.changes()
            
            # æ„å»ºæ›´å‹å¥½çš„å˜æ›´ä¿¡æ¯
            formatted_changes = {
                'id': mr.id,
                'iid': mr.iid,
                'title': mr.title,
                'state': mr.state,
                'created_at': mr.created_at,
                'updated_at': mr.updated_at,
                'source_branch': mr.source_branch,
                'target_branch': mr.target_branch,
                'changes': []
            }
            
            # å¤„ç†æ¯ä¸ªæ–‡ä»¶çš„å˜æ›´
            for change in changes['changes']:
                formatted_changes['changes'].append({
                    'old_path': change.get('old_path'),
                    'new_path': change.get('new_path'),
                    'diff': change.get('diff'),
                    'new_file': change.get('new_file', False),
                    'renamed_file': change.get('renamed_file', False),
                    'deleted_file': change.get('deleted_file', False)
                })
            
            logger.debug(f"Successfully got changes for MR: {mr.title}")
            return formatted_changes
            
        except Exception as e:
            error_msg = f"Failed to get MR changes: {str(e)}"
            logger.error(error_msg)
            raise

    def get_mr_details(self, url: str) -> Dict[str, Any]:
        """
        è·å– MR çš„è¯¦ç»†ä¿¡æ¯
        
        Args:
            url: GitLab MR URL
            
        Returns:
            åŒ…å« MR è¯¦ç»†ä¿¡æ¯çš„å­—å…¸
        """
        logger.info(f"Getting MR details for: {url}")
        try:
            parsed_info = self.parse_mr_url(url)
            project = self.get_project(parsed_info['project_id'])
            mr = self.get_merge_request(project, parsed_info['mr_iid'])
            
            details = {
                'id': mr.id,
                'iid': mr.iid,
                'title': mr.title,
                'description': mr.description,
                'state': mr.state,
                'merged': mr.state == 'merged',
                'merged_at': getattr(mr, 'merged_at', None),
                'created_at': mr.created_at,
                'updated_at': mr.updated_at,
                'source_branch': mr.source_branch,
                'target_branch': mr.target_branch,
                'author': {
                    'id': mr.author['id'],
                    'name': mr.author['name'],
                    'username': mr.author['username']
                },
                'labels': mr.labels,
                'web_url': mr.web_url
            }
            
            logger.debug(f"Successfully got details for MR: {mr.title}")
            return details
            
        except Exception as e:
            error_msg = f"Failed to get MR details: {str(e)}"
            logger.error(error_msg)
            raise
    
        
    def analyze_code_changes(self, changes: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æä»£ç å˜æ›´"""
        logger.info("Starting code analysis")
        review_results = {
            'summary': {
                'total_files': len(changes),
                'total_additions': 0,
                'total_deletions': 0,
                'file_types': {}
            },
            'files_analysis': [],
            'java_analysis': {
                'files_analyzed': 0,
                'total_issues': 0,
                'critical_issues': 0,
                'warnings': 0,
                'suggestions': 0,
                'file_results': []
            }
        }

        for change in changes:
            try:
                file_path = change.get('new_path', '')
                if not file_path or not change.get('diff'):
                    continue

                # åŸºæœ¬æ–‡ä»¶åˆ†æ
                file_analysis = self._analyze_single_file(change)
                review_results['files_analysis'].append(file_analysis)
                
                # æ”¶é›†è¡Œè¯„è®º
                if file_analysis.get('line_comments'):
                    review_results['line_comments'][file_path] = file_analysis['line_comments']
                
                # Javaç‰¹å®šåˆ†æ
                if self._is_java_file(file_path):
                    java_analysis = self._analyze_java_file(change)
                    if java_analysis:
                        review_results['java_analysis']['files_analyzed'] += 1
                        # ... å…¶ä»– Java åˆ†æç»Ÿè®¡ ...
                        
                        # æ”¶é›† Java åˆ†æäº§ç”Ÿçš„è¡Œè¯„è®º
                        if java_analysis.get('line_comments'):
                            if file_path not in review_results['line_comments']:
                                review_results['line_comments'][file_path] = {}
                            review_results['line_comments'][file_path].update(
                                java_analysis['line_comments']
                            )
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                if change.get('new_path'):
                    file_ext = change['new_path'].split('.')[-1] if '.' in change['new_path'] else 'no_extension'
                    review_results['summary']['file_types'][file_ext] = \
                        review_results['summary']['file_types'].get(file_ext, 0) + 1

                # ç»Ÿè®¡å˜æ›´è¡Œæ•°
                if change.get('diff'):
                    additions = len(re.findall(r'^\+[^+]', change['diff'], re.MULTILINE))
                    deletions = len(re.findall(r'^-[^-]', change['diff'], re.MULTILINE))
                    review_results['summary']['total_additions'] += additions
                    review_results['summary']['total_deletions'] += deletions
                    
            except Exception as e:
                logger.exception(f"Error analyzing file: {change.get('new_path', 'unknown file')}")
                
        return review_results
    def _analyze_single_file(self, change: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        file_path = change.get('new_path', '')
        file_analysis = {
            'file_path': file_path,
            'change_type': self._determine_change_type(change),
            'issues': [],
            'warnings': [],
            'suggestions': [],
            'line_comments': {}  # æ·»åŠ è¡Œè¯„è®ºæ”¶é›†
        }

        try:
            if change.get('diff'):
                current_line = 0
                
                # åˆ†ædiffè·å–è¡Œå·
                diff_lines = change['diff'].split('\n')
                for line in diff_lines:
                    if line.startswith('@@'):
                        match = re.search(r'\+(\d+)', line)
                        if match:
                            current_line = int(match.group(1)) - 1
                        continue
                    
                    if line.startswith('+'):
                        current_line += 1
                        # åˆ†ææ–°æ·»åŠ çš„ä»£ç è¡Œ
                        line_issues = self._analyze_code_line(line[1:], file_path)
                        if line_issues:
                            file_analysis['line_comments'][current_line] = line_issues
                    
                    elif line.startswith(' '):
                        current_line += 1

        except Exception as e:
            logger.exception(f"Error analyzing file: {file_path}")
            file_analysis['issues'].append(f"æ–‡ä»¶åˆ†æé”™è¯¯: {str(e)}")

        return file_analysis

    def _is_java_file(self, file_path: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯Javaæ–‡ä»¶"""
        return file_path and file_path.endswith('.java')

    def _analyze_java_file(self, change: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æJavaæ–‡ä»¶"""
        try:
            if not change.get('diff'):
                return None

            file_path = change.get('new_path', '')
            logger.info(f"Analyzing Java file: {file_path}")

            # ä»diffä¸­æå–æ–°ä»£ç 
            new_code = '\n'.join(
                line[1:] for line in change['diff'].split('\n')
                if line.startswith('+') and not line.startswith('++')
            )

            if not new_code.strip():
                return None

            # æ‰§è¡ŒJavaä»£ç åˆ†æ
            analysis_result = self.java_analyzer.analyze_java_file(new_code, file_path)
            
            return {
                'file_path': file_path,
                'issues': analysis_result.get('issues', []),
                'warnings': analysis_result.get('warnings', []),
                'suggestions': analysis_result.get('suggestions', []),
                'metrics': analysis_result.get('metrics', {}),
                'quality_score': self.java_analyzer._calculate_quality_score(analysis_result)
            }

        except Exception as e:
            logger.exception(f"Error in Java analysis for file {change.get('new_path')}")
            return None

    def format_java_review_comment(self, java_analysis: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–Javaä»£ç è¯„å®¡è¯„è®º"""
        comment_parts = []
        comment_parts.append("## Javaä»£ç è¯„å®¡ç»“æœ\n")
        
        # æ€»ä½“ç»Ÿè®¡
        comment_parts.append("### ğŸ“Š æ€»ä½“ç»Ÿè®¡")
        comment_parts.append(f"- åˆ†ææ–‡ä»¶æ•°: {java_analysis['files_analyzed']}")
        comment_parts.append(f"- æ€»é—®é¢˜æ•°: {java_analysis['total_issues']}")
        comment_parts.append(f"- ä¸¥é‡é—®é¢˜: {java_analysis['critical_issues']}")
        comment_parts.append(f"- è­¦å‘Š: {java_analysis['warnings']}")
        comment_parts.append(f"- å»ºè®®: {java_analysis['suggestions']}\n")
        
        # æ–‡ä»¶è¯¦ç»†åˆ†æ
        if java_analysis['file_results']:
            comment_parts.append("### ğŸ“ è¯¦ç»†åˆ†æ")
            for file_result in java_analysis['file_results']:
                comment_parts.append(f"\n#### {file_result['file_path']}")
                comment_parts.append(f"ä»£ç è´¨é‡å¾—åˆ†: {file_result['quality_score']}/100")
                
                if file_result['issues']:
                    comment_parts.append("\nâŒ **ä¸¥é‡é—®é¢˜:**")
                    for issue in file_result['issues']:
                        comment_parts.append(f"- {issue}")
                
                if file_result['warnings']:
                    comment_parts.append("\nâš ï¸ **è­¦å‘Š:**")
                    for warning in file_result['warnings']:
                        comment_parts.append(f"- {warning}")
                
                if file_result['suggestions']:
                    comment_parts.append("\nğŸ’¡ **å»ºè®®:**")
                    for suggestion in file_result['suggestions']:
                        comment_parts.append(f"- {suggestion}")
                        
                if file_result.get('metrics'):
                    comment_parts.append("\nğŸ“ˆ **æŒ‡æ ‡:**")
                    for metric, value in file_result['metrics'].items():
                        comment_parts.append(f"- {metric}: {value}")
        
        return '\n'.join(comment_parts)
    
    
    def _format_review_comment(self, review_results: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–ä»£ç è¯„å®¡è¯„è®º
        
        Args:
            review_results: è¯„å®¡ç»“æœå­—å…¸
            
        Returns:
            æ ¼å¼åŒ–åçš„è¯„è®ºå­—ç¬¦ä¸²
        """
        logger.debug("Formatting review comment")
        comment_parts = []
        
        # æ·»åŠ æ ‡é¢˜
        comment_parts.append("# ä»£ç è¯„å®¡æŠ¥å‘Š ğŸ“\n")
        
        # MRåŸºæœ¬ä¿¡æ¯
        if 'mr_info' in review_results:
            comment_parts.append("## åˆå¹¶è¯·æ±‚ä¿¡æ¯")
            mr_info = review_results['mr_info']
            comment_parts.append(f"- æ ‡é¢˜: {mr_info['title']}")
            comment_parts.append(f"- ä½œè€…: {mr_info['author']['name']} (@{mr_info['author']['username']})")
            comment_parts.append(f"- çŠ¶æ€: {mr_info['state']}")
            comment_parts.append(f"- åˆ›å»ºæ—¶é—´: {mr_info['created_at']}\n")
        
        # å˜æ›´æ¦‚è¦
        if 'summary' in review_results:
            comment_parts.append("## å˜æ›´æ¦‚è¦ ğŸ“Š")
            summary = review_results['summary']
            comment_parts.append(f"- å˜æ›´æ–‡ä»¶æ€»æ•°: {summary['total_files']}")
            comment_parts.append(f"- æ–°å¢è¡Œæ•°: {summary['total_additions']}")
            comment_parts.append(f"- åˆ é™¤è¡Œæ•°: {summary['total_deletions']}")
            
            # æ–‡ä»¶ç±»å‹ç»Ÿè®¡
            if summary.get('file_types'):
                comment_parts.append("\n### æ–‡ä»¶ç±»å‹åˆ†å¸ƒ")
                for file_type, count in summary['file_types'].items():
                    comment_parts.append(f"- {file_type}: {count}ä¸ªæ–‡ä»¶")
            comment_parts.append("")
        
        # æ–‡ä»¶åˆ†æç»“æœ
        if review_results.get('files_analysis'):
            comment_parts.append("## æ–‡ä»¶åˆ†æ ğŸ”")
            for file_analysis in review_results['files_analysis']:
                if file_analysis.get('issues') or file_analysis.get('warnings') or file_analysis.get('suggestions'):
                    comment_parts.append(f"\n### {file_analysis['file_path']}")
                    
                    # é—®é¢˜
                    if file_analysis.get('issues'):
                        comment_parts.append("\n#### âŒ é—®é¢˜")
                        for issue in file_analysis['issues']:
                            comment_parts.append(f"- {issue}")
                    
                    # è­¦å‘Š
                    if file_analysis.get('warnings'):
                        comment_parts.append("\n#### âš ï¸ è­¦å‘Š")
                        for warning in file_analysis['warnings']:
                            comment_parts.append(f"- {warning}")
                    
                    # å»ºè®®
                    if file_analysis.get('suggestions'):
                        comment_parts.append("\n#### ğŸ’¡ å»ºè®®")
                        for suggestion in file_analysis['suggestions']:
                            comment_parts.append(f"- {suggestion}")
                            
        # ä»£ç è´¨é‡æŒ‡æ ‡
        metrics = self._calculate_quality_metrics(review_results)
        if metrics:
            comment_parts.append("\n## ä»£ç è´¨é‡æŒ‡æ ‡ ğŸ“ˆ")
            for metric, value in metrics.items():
                comment_parts.append(f"- {metric}: {value}")
        
        # æœ€ä½³å®è·µå»ºè®®
        best_practices = self._get_best_practices_suggestions(review_results)
        if best_practices:
            comment_parts.append("\n## æœ€ä½³å®è·µå»ºè®® âœ¨")
            for practice in best_practices:
                comment_parts.append(f"- {practice}")
        
        # å®‰å…¨æ€§æ£€æŸ¥
        security_issues = self._check_security_issues(review_results)
        if security_issues:
            comment_parts.append("\n## å®‰å…¨æ€§æ£€æŸ¥ ğŸ”’")
            for issue in security_issues:
                comment_parts.append(f"- âš ï¸ {issue}")
        
        # æ€»ç»“
        comment_parts.append("\n## æ€»ç»“å»ºè®® ğŸ“‹")
        recommendations = self._generate_recommendations(review_results)
        for rec in recommendations:
            comment_parts.append(f"- {rec}")
            
        # æ³¨è„š
        comment_parts.append("\n---")
        comment_parts.append("*æ­¤è¯„å®¡æŠ¥å‘Šç”±è‡ªåŠ¨ä»£ç è¯„å®¡å·¥å…·ç”Ÿæˆ*")
        
        return "\n".join(comment_parts)

    def _calculate_quality_metrics(self, review_results: Dict[str, Any]) -> Dict[str, Any]:
        """è®¡ç®—ä»£ç è´¨é‡æŒ‡æ ‡"""
        metrics = {}
        
        if 'summary' in review_results:
            total_changes = (review_results['summary']['total_additions'] + 
                           review_results['summary']['total_deletions'])
            
            if total_changes > 0:
                # è®¡ç®—å˜æ›´è§„æ¨¡
                metrics['å˜æ›´è§„æ¨¡'] = 'å¤§å‹å˜æ›´' if total_changes > 500 else 'ä¸­å‹å˜æ›´' if total_changes > 200 else 'å°å‹å˜æ›´'
                
                # è®¡ç®—æ–‡ä»¶å½±å“èŒƒå›´
                files_count = review_results['summary']['total_files']
                metrics['æ–‡ä»¶å½±å“èŒƒå›´'] = f"{files_count}ä¸ªæ–‡ä»¶"
        
        # è®¡ç®—é—®é¢˜å¯†åº¦
        total_issues = 0
        for file_analysis in review_results.get('files_analysis', []):
            total_issues += (len(file_analysis.get('issues', [])) + 
                           len(file_analysis.get('warnings', [])))
        
        if total_issues > 0:
            metrics['é—®é¢˜å¯†åº¦'] = f"{total_issues}ä¸ªé—®é¢˜/è­¦å‘Š"
            
        return metrics

    def _get_best_practices_suggestions(self, review_results: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæœ€ä½³å®è·µå»ºè®®"""
        suggestions = []
        
        # åŸºäºæ–‡ä»¶åˆ†æç»“æœç”Ÿæˆå»ºè®®
        for file_analysis in review_results.get('files_analysis', []):
            for suggestion in file_analysis.get('suggestions', []):
                if suggestion not in suggestions:
                    suggestions.append(suggestion)
        
        return suggestions

    def _check_security_issues(self, review_results: Dict[str, Any]) -> List[str]:
        """æ£€æŸ¥å®‰å…¨ç›¸å…³é—®é¢˜"""
        security_issues = []
        
        for file_analysis in review_results.get('files_analysis', []):
            for issue in file_analysis.get('issues', []):
                # è¯†åˆ«å®‰å…¨ç›¸å…³é—®é¢˜
                if any(keyword in issue.lower() for keyword in 
                      ['security', 'secure', 'vulnerability', 'unsafe', 'injection', 'xss', 'csrf']):
                    security_issues.append(issue)
        
        return security_issues

    def _generate_recommendations(self, review_results: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ€»ä½“å»ºè®®"""
        recommendations = []
        
        # åŸºäºé—®é¢˜æ•°é‡ç”Ÿæˆå»ºè®®
        total_issues = 0
        total_warnings = 0
        for file_analysis in review_results.get('files_analysis', []):
            total_issues += len(file_analysis.get('issues', []))
            total_warnings += len(file_analysis.get('warnings', []))
        
        if total_issues > 0:
            recommendations.append(f"éœ€è¦è§£å†³çš„ä¸¥é‡é—®é¢˜: {total_issues}ä¸ª")
        if total_warnings > 0:
            recommendations.append(f"éœ€è¦å…³æ³¨çš„è­¦å‘Š: {total_warnings}ä¸ª")
        return recommendations


    def _submit_line_comments(self, mr: ProjectMergeRequest, line_comments: Dict[str, Dict[int, List[str]]]) -> None:
        """
        æäº¤è¡Œçº§åˆ«è¯„è®º
        
        Args:
            mr: MRå¯¹è±¡
            line_comments: è¡Œè¯„è®ºå­—å…¸ {file_path: {line_number: [comments]}}
        """
        try:
            # é…ç½®æ‰¹å¤„ç†å¤§å°
            BATCH_SIZE = 5
            
            # æŒ‰æ–‡ä»¶å¤„ç†è¯„è®º
            for file_path, comments in line_comments.items():
                logger.info(f"Creating comments for file: {file_path}")
                
                if not comments:
                    continue
                    
                # ä½¿ç”¨æ‰¹é‡å¤„ç†æ–¹æ³•æäº¤è¯„è®º
                self._create_batch_comments(
                    mr=mr,
                    file_path=file_path,
                    comments=comments,
                    batch_size=BATCH_SIZE
                )
                
                logger.info(f"Successfully submitted comments for {file_path}")
                        
        except Exception as e:
            logger.exception("Failed to submit line comments")
            raise

    def _create_batch_comments(self, mr: ProjectMergeRequest, file_path: str, 
                            comments: Dict[int, List[str]], batch_size: int = 5) -> None:
        """
        æ‰¹é‡åˆ›å»ºè¯„è®º
        
        Args:
            mr: MRå¯¹è±¡
            file_path: æ–‡ä»¶è·¯å¾„
            comments: è¯„è®ºå­—å…¸ {line_number: [comments]}
            batch_size: æ‰¹æ¬¡å¤§å°
        """
        try:
            # è·å–å¿…è¦çš„SHAå€¼
            base_sha = mr.diff_refs['base_sha']
            head_sha = mr.diff_refs['head_sha']
            start_sha = mr.diff_refs.get('start_sha', base_sha)
            
            # å°†è¯„è®ºæŒ‰æ‰¹æ¬¡å¤„ç†
            comment_items = list(comments.items())
            total_batches = len(comment_items) // batch_size + (1 if len(comment_items) % batch_size > 0 else 0)
            
            for batch_index in range(total_batches):
                start_idx = batch_index * batch_size
                end_idx = min(start_idx + batch_size, len(comment_items))
                batch = dict(comment_items[start_idx:end_idx])
                
                logger.debug(f"Processing batch {batch_index + 1}/{total_batches} for {file_path}")
                
                # å¤„ç†å½“å‰æ‰¹æ¬¡çš„è¯„è®º
                for line_num, issues in batch.items():
                    try:
                        # æ ¼å¼åŒ–è¯„è®ºå†…å®¹
                        comment_body = self._format_line_comment_body(issues)
                        
                        # åˆ›å»ºè¯„è®º
                        position_data = {
                            'base_sha': base_sha,
                            'start_sha': start_sha,
                            'head_sha': head_sha,
                            'position_type': 'text',
                            'new_path': file_path,
                            'new_line': line_num,
                            'old_path': file_path,
                            'old_line': None
                        }
                        
                        mr.discussions.create({
                            'body': comment_body,
                            'position': position_data
                        })
                        
                        logger.debug(f"Created comment for line {line_num} in {file_path}")
                        
                    except Exception as e:
                        logger.error(f"Failed to create comment for line {line_num} in {file_path}: {str(e)}")
                
                # æ·»åŠ å»¶è¿Ÿä»¥é¿å…è§¦å‘APIé™åˆ¶
                if batch_index < total_batches - 1:  # å¦‚æœä¸æ˜¯æœ€åä¸€æ‰¹ï¼Œæ·»åŠ å»¶è¿Ÿ
                    time.sleep(1)
                
            logger.info(f"Completed submitting {len(comments)} comments for {file_path}")
                
        except Exception as e:
            logger.exception(f"Failed to create batch comments for {file_path}")
            raise

    
    
    def review_mr(self, url: str, batch_size: int = 5) -> Dict[str, Any]:
        """
        æ‰§è¡ŒMRè¯„å®¡
        
        Args:
            url: MR URL
            batch_size: è¯„è®ºæ‰¹å¤„ç†å¤§å°
            
        Returns:
            è¯„å®¡ç»“æœ
        """
        logger.info(f"Starting code review for MR: {url}")
        
        try:
            # è·å–MRä¿¡æ¯
            parsed_info = self.parse_mr_url(url)
            project = self.get_project(parsed_info['project_id'])
            mr = self.get_merge_request(project, parsed_info['mr_iid'])
            
            # æ£€æŸ¥MRçŠ¶æ€
            if mr.state not in ['opened', 'reopened']:
                raise ValueError(f"MR is not open for review (state: {mr.state})")
            
            # è·å–å˜æ›´
            changes = self.get_mr_changes(url)
            mr_details = self.get_mr_details(url)
            
            # åˆ†æä»£ç 
            review_results = self.analyze_code_changes(changes['changes'])
            
            # ä½¿ç”¨ AI è¿›è¡Œä»£ç è¯„å®¡
            ai_review_results = self.ai_reviewer.review_code_changes(changes['changes'])
            if ai_review_results.get('success'):
                review_results['ai_review'] = ai_review_results
        
            
            # æ„å»ºç»“æœ
            results = {
                'mr_info': {
                    'title': mr_details['title'],
                    'author': mr_details['author'],
                    'state': mr_details['state'],
                    'created_at': mr_details['created_at']
                },
                'changes': changes['changes'],
                **review_results
            }
            
            # æäº¤è¯„è®ºï¼ˆä½¿ç”¨æ‰¹å¤„ç†ï¼‰
            self._submit_review_results(mr, results, batch_size)
            
            logger.info("Code review completed successfully")
            return results
            
        except Exception as e:
            logger.exception("Failed to complete code review")
            raise


    def _submit_review_results(self, mr: ProjectMergeRequest, review_results: Dict[str, Any], 
                             batch_size: int = 5) -> None:
        """
        æäº¤è¯„å®¡ç»“æœ
        
        Args:
            mr: MRå¯¹è±¡
            review_results: è¯„å®¡ç»“æœ
            batch_size: æ‰¹å¤„ç†å¤§å°
        """
        try:
            # æ·»åŠ å»¶è¿Ÿä»¥é¿å…è¯·æ±‚è¿‡å¿«
            sleep(1)
            
            # 1. æäº¤æ¦‚è¿°è¯„è®º
            self._submit_overview_comment(mr, review_results)
            
            # 2. æ‰¹é‡æäº¤è¡Œè¯„è®º
            self._submit_line_comments(mr, review_results)
            
            logger.info("Successfully submitted all review comments")
            
        except Exception as e:
            logger.exception("Failed to submit review results")
            raise

    def _submit_overview_comment(self, mr: ProjectMergeRequest, review_results: Dict[str, Any]) -> None:
        """
        æäº¤æ¦‚è¿°è¯„è®º
        
        Args:
            mr: MRå¯¹è±¡
            review_results: è¯„å®¡ç»“æœ
        """
        try:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†APIé™åˆ¶
            self._handle_rate_limits()
            
            # ç”Ÿæˆå¹¶æäº¤è¯„è®º
            overview_comment = self._format_review_comment(review_results)
            
             # 2. å¦‚æœæœ‰ AI è¯„å®¡ç»“æœï¼Œæ·»åŠ åˆ°è¯„è®ºä¸­
            if 'ai_review' in review_results:
                ai_comment = self.ai_reviewer.format_review_comment(review_results['ai_review'])
                overview_comment = f"{overview_comment}\n\n{ai_comment}"
            
            mr.notes.create({'body': overview_comment})
            
            logger.info("Successfully submitted overview comment")
            
        except Exception as e:
            logger.exception("Failed to submit overview comment")
            raise

    def _submit_line_comments(self, mr: ProjectMergeRequest, review_results: Dict[str, Any]) -> None:
        """æäº¤è¡Œçº§åˆ«è¯„è®º"""
        try:
            # 1. å¤„ç†å¸¸è§„åˆ†æçš„è¡Œè¯„è®º
            for file_analysis in review_results.get('files_analysis', []):
                if file_analysis.get('line_comments'):
                    self._create_line_comments(
                        mr, 
                        file_analysis['file_path'],
                        file_analysis['line_comments']
                    )
            
            # 2. å¤„ç† AI åˆ†æçš„è¡Œè¯„è®º
            if 'ai_review' in review_results:
                for file_review in review_results['ai_review'].get('file_reviews', []):
                    if file_review.get('line_issues'):
                        comments = self.ai_reviewer._format_line_comment(
                            file_review['file_path'],
                            file_review['line_issues']
                        )
                        self._create_line_comments(
                            mr,
                            file_review['file_path'],
                            comments
                        )
                        
        except Exception as e:
            logger.exception("Failed to submit line comments")
            raise
    
    def _create_line_comments(
        self, 
        mr: ProjectMergeRequest, 
        file_path: str, 
        comments: Dict[int, List[str]]
    ) -> None:
        """åˆ›å»ºè¡Œçº§åˆ«è¯„è®º"""
        try:
            base_sha = mr.diff_refs['base_sha']
            head_sha = mr.diff_refs['head_sha']
            start_sha = mr.diff_refs.get('start_sha', base_sha)
            
            for line_num, comment_list in comments.items():
                comment_body = "\n".join([
                    f"- {comment}" for comment in comment_list
                ])
                
                position_data = {
                    'base_sha': base_sha,
                    'start_sha': start_sha,
                    'head_sha': head_sha,
                    'position_type': 'text',
                    'new_path': file_path,
                    'new_line': line_num,
                    'old_path': file_path,
                    'old_line': None
                }
                
                mr.discussions.create({
                    'body': comment_body,
                    'position': position_data
                })
                
                logger.debug(f"Created comment for line {line_num} in {file_path}")
                
        except Exception as e:
            logger.exception(f"Failed to create line comments for {file_path}")
            raise    
    
    def _get_file_type_analyzer(self, file_path: str) -> Any:
        """
        è·å–æ–‡ä»¶ç±»å‹å¯¹åº”çš„åˆ†æå™¨
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            åˆ†æå™¨å®ä¾‹
        """
        if file_path.endswith('.java'):
            return self.java_analyzer
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å…¶ä»–ç±»å‹çš„åˆ†æå™¨
        return None

    def _should_analyze_file(self, file_path: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ†æè¯¥æ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦éœ€è¦åˆ†æ
        """
        # æ’é™¤ä¸éœ€è¦åˆ†æçš„æ–‡ä»¶
        exclude_patterns = [
            r'\.git/',
            r'\.idea/',
            r'\.vscode/',
            r'target/',
            r'build/',
            r'dist/',
            r'node_modules/',
            r'\.md$',
            r'\.txt$',
            r'\.log$',
            r'\.lock$',
            r'package-lock\.json$'
        ]
        
        return not any(re.search(pattern, file_path) for pattern in exclude_patterns)

    def _get_diff_context(self, diff: str, line_num: int, context_lines: int = 3) -> str:
        """
        è·å–diffä¸Šä¸‹æ–‡
        
        Args:
            diff: diffå†…å®¹
            line_num: ç›®æ ‡è¡Œå·
            context_lines: ä¸Šä¸‹æ–‡è¡Œæ•°
            
        Returns:
            ä¸Šä¸‹æ–‡ä»£ç 
        """
        lines = diff.split('\n')
        start = max(0, line_num - context_lines - 1)
        end = min(len(lines), line_num + context_lines)
        
        context = []
        for i, line in enumerate(lines[start:end], start=start+1):
            prefix = '> ' if i == line_num else '  '
            context.append(f"{prefix}{line}")
            
        return '\n'.join(context)

    

    def _submit_line_comments(self, mr: ProjectMergeRequest, file_path: str, 
                            line_comments: Dict[int, List[str]], change: Dict[str, Any]) -> None:
        """
        æäº¤è¡Œçº§åˆ«è¯„è®º
        
        Args:
            mr: MR å¯¹è±¡
            file_path: æ–‡ä»¶è·¯å¾„
            line_comments: è¡Œè¯„è®ºå­—å…¸
            change: å˜æ›´ä¿¡æ¯
        """
        try:
            logger.info(f"Submitting line comments for file: {file_path}")
            
            # è·å–å¿…è¦çš„ SHA
            base_sha = mr.diff_refs['base_sha']
            head_sha = mr.diff_refs['head_sha']
            start_sha = mr.diff_refs.get('start_sha', base_sha)
            
            # å¯¹æ¯ä¸ªæœ‰è¯„è®ºçš„è¡Œåˆ›å»ºè¯„è®º
            for line_num, comments in line_comments.items():
                if not comments:
                    continue
                    
                # æ ¼å¼åŒ–è¯„è®ºå†…å®¹
                comment_body = "ğŸ” ä»£ç è¯„å®¡æ„è§ï¼š\n\n" + "\n".join([
                    f"- {comment}" for comment in comments
                ])
                
                try:
                    # åˆ›å»ºè¡Œçº§åˆ«è¯„è®º
                    mr.discussions.create({
                        'body': comment_body,
                        'position': {
                            'base_sha': base_sha,
                            'start_sha': start_sha,
                            'head_sha': head_sha,
                            'position_type': 'text',
                            'new_path': file_path,
                            'new_line': line_num,
                            'old_path': file_path,
                            'old_line': None
                        }
                    })
                    
                    logger.debug(f"Created comment for line {line_num} in {file_path}")
                    
                except Exception as e:
                    logger.error(f"Failed to create comment for line {line_num} in {file_path}: {str(e)}")
                    
            logger.info(f"Successfully submitted {len(line_comments)} line comments for {file_path}")
            
        except Exception as e:
            logger.exception(f"Failed to submit line comments for {file_path}")
            raise

    def _collect_line_comments(self, change: Dict[str, Any], review_results: Dict[str, Any]) -> Dict[int, List[str]]:
        """
        æ”¶é›†æ–‡ä»¶çš„è¡Œçº§åˆ«è¯„è®º
        
        Args:
            change: æ–‡ä»¶å˜æ›´ä¿¡æ¯
            review_results: è¯„å®¡ç»“æœ
            
        Returns:
            è¡Œå·åˆ°è¯„è®ºçš„æ˜ å°„å­—å…¸
        """
        line_comments = {}
        file_path = change.get('new_path', '')
        
        if not file_path or not change.get('diff'):
            return line_comments

        try:
            # è§£æ diff è·å–è¡Œå·ä¿¡æ¯
            diff_lines = change['diff'].split('\n')
            current_line = 0
            
            for line in diff_lines:
                # å¤„ç† diff å¤´éƒ¨ï¼Œæ›´æ–°å½“å‰è¡Œå·
                if line.startswith('@@'):
                    match = re.search(r'\+(\d+)', line)
                    if match:
                        current_line = int(match.group(1)) - 1
                    continue
                
                # åªåˆ†ææ–°å¢æˆ–ä¿®æ”¹çš„è¡Œ
                if line.startswith('+'):
                    current_line += 1
                    code_line = line[1:]  # å»æ‰ '+' å‰ç¼€
                    
                    # æ ¹æ®æ–‡ä»¶ç±»å‹è¿›è¡Œç›¸åº”çš„åˆ†æ
                    if file_path.endswith('.java'):
                        issues = self.java_analyzer.analyze_java_line(code_line)
                        if issues:
                            line_comments[current_line] = issues
                    
                elif line.startswith(' '):
                    current_line += 1
            
            logger.debug(f"Collected {len(line_comments)} line comments for {file_path}")
            
        except Exception as e:
            logger.exception(f"Error collecting line comments for {file_path}")
        
        return line_comments
    def _validate_position_params(self, mr: ProjectMergeRequest, file_path: str, 
                                line_num: int) -> Dict[str, Any]:
        """
        éªŒè¯å¹¶æ„å»ºä½ç½®å‚æ•°
        
        Args:
            mr: MRå¯¹è±¡
            file_path: æ–‡ä»¶è·¯å¾„
            line_num: è¡Œå·
            
        Returns:
            ä½ç½®å‚æ•°å­—å…¸
        """
        try:
            # è·å–å¿…è¦çš„SHAå€¼
            diff_refs = mr.diff_refs
            if not all([diff_refs.get('base_sha'), diff_refs.get('head_sha')]):
                raise ValueError("Missing required diff refs")

            position = {
                'base_sha': diff_refs['base_sha'],
                'start_sha': diff_refs.get('start_sha', diff_refs['base_sha']),
                'head_sha': diff_refs['head_sha'],
                'position_type': 'text',
                'new_path': file_path,
                'new_line': line_num,
                'old_path': file_path,
                'old_line': None
            }

            logger.debug(f"Generated position params for {file_path}:{line_num}")
            return position

        except Exception as e:
            logger.error(f"Failed to validate position params: {str(e)}")
            raise

    def _create_line_comment(self, mr: ProjectMergeRequest, position: Dict[str, Any], 
                           comment: str) -> None:
        """
        åˆ›å»ºå•ä¸ªè¡Œè¯„è®º
        
        Args:
            mr: MRå¯¹è±¡
            position: ä½ç½®å‚æ•°
            comment: è¯„è®ºå†…å®¹
        """
        try:
            discussion = mr.discussions.create({
                'body': comment,
                'position': position
            })
            
            logger.debug(f"Created comment at {position['new_path']}:{position['new_line']}")
            return discussion

        except gitlab.exceptions.GitlabError as e:
            logger.error(f"GitLab API error while creating comment: {str(e)}")
            raise
        except Exception as e:
            logger.error(f"Unexpected error while creating comment: {str(e)}")
            raise

    def _format_line_comment(self, issues: List[str]) -> str:
        """
        æ ¼å¼åŒ–è¡Œè¯„è®ºå†…å®¹
        
        Args:
            issues: é—®é¢˜åˆ—è¡¨
            
        Returns:
            æ ¼å¼åŒ–çš„è¯„è®ºå­—ç¬¦ä¸²
        """
        comment_parts = ["ğŸ” ä»£ç è¯„å®¡æ„è§ï¼š\n"]
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç±»
        critical_issues = [i for i in issues if "âŒ" in i]
        warnings = [i for i in issues if "âš ï¸" in i]
        suggestions = [i for i in issues if "ğŸ’¡" in i]
        
        if critical_issues:
            comment_parts.append("\nä¸¥é‡é—®é¢˜ï¼š")
            comment_parts.extend([f"- {issue}" for issue in critical_issues])
            
        if warnings:
            comment_parts.append("\nè­¦å‘Šï¼š")
            comment_parts.extend([f"- {issue}" for issue in warnings])
            
        if suggestions:
            comment_parts.append("\nå»ºè®®ï¼š")
            comment_parts.extend([f"- {issue}" for issue in suggestions])
            
        return "\n".join(comment_parts)

    def _handle_rate_limits(self, retry_count: int = 3, delay: int = 5) -> None:
        """
        å¤„ç†APIé€Ÿç‡é™åˆ¶
        
        Args:
            retry_count: é‡è¯•æ¬¡æ•°
            delay: å»¶è¿Ÿç§’æ•°
        """
        import time

        try:
            # è·å–å½“å‰ç”¨æˆ·çš„è¯·æ±‚ç»Ÿè®¡
            # æ³¨æ„ï¼šè¿™éœ€è¦ API ç‰ˆæœ¬ >= 12.2ï¼Œä¸”ç”¨æˆ·éœ€è¦æœ‰è¶³å¤Ÿæƒé™
            user = self.gl.user
            if not user:
                logger.warning("Unable to get user info for rate limit check")
                return

            # æ£€æŸ¥å“åº”å¤´ä¸­çš„é€Ÿç‡é™åˆ¶ä¿¡æ¯
            headers = user.manager.gitlab.http_list(user.path)[2]
            remaining = int(headers.get('RateLimit-Remaining', 0))
            reset_time = int(headers.get('RateLimit-Reset', 0))

            if remaining < 10:  # å¦‚æœå‰©ä½™è¯·æ±‚æ•°å¾ˆå°‘
                wait_time = reset_time - int(time.time())
                if wait_time > 0:
                    logger.warning(f"Rate limit almost reached. Waiting {wait_time} seconds...")
                    time.sleep(min(wait_time, 60))  # æœ€å¤šç­‰å¾…60ç§’

        except Exception as e:
            logger.warning(f"Failed to check rate limits: {str(e)}")
            # å¦‚æœæ— æ³•æ£€æŸ¥é€Ÿç‡é™åˆ¶ï¼Œæ·»åŠ ä¸€ä¸ªå°çš„å»¶è¿Ÿ
            time.sleep(1)

    def _chunk_comments(self, comments: List[str], chunk_size: int = 5) -> List[List[str]]:
        """
        å°†è¯„è®ºåˆ†å—ä»¥é¿å…è¶…è¿‡APIé™åˆ¶
        
        Args:
            comments: è¯„è®ºåˆ—è¡¨
            chunk_size: æ¯å—çš„å¤§å°
            
        Returns:
            è¯„è®ºå—åˆ—è¡¨
        """
        return [comments[i:i + chunk_size] for i in range(0, len(comments), chunk_size)]

    def analyze_code_changes(self, changes: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æä»£ç å˜æ›´"""
        logger.info("Starting code analysis")
        review_results = {
            'summary': {
                'total_files': len(changes),
                'total_additions': 0,
                'total_deletions': 0,
                'file_types': {}
            },
            'files_analysis': [],
            'line_comments': {},  # æ·»åŠ è¡Œè¯„è®ºæ”¶é›†
            'java_analysis': {
                'files_analyzed': 0,
                'total_issues': 0,
                'critical_issues': 0,
                'warnings': 0,
                'suggestions': 0,
                'file_results': []
            }
        }

        for change in changes:
            try:
                file_path = change.get('new_path', '')
                if not file_path or not change.get('diff'):
                    continue

                # åŸºæœ¬æ–‡ä»¶åˆ†æ
                file_analysis = self._analyze_single_file(change)
                review_results['files_analysis'].append(file_analysis)
                
                # æ”¶é›†è¡Œè¯„è®º
                if file_analysis.get('line_comments'):
                    review_results['line_comments'][file_path] = file_analysis['line_comments']
                
                # Javaç‰¹å®šåˆ†æ
                if self._is_java_file(file_path):
                    java_analysis = self._analyze_java_file(change)
                    if java_analysis:
                        review_results['java_analysis']['files_analyzed'] += 1
                        # ... å…¶ä»– Java åˆ†æç»Ÿè®¡ ...
                        
                        # æ”¶é›† Java åˆ†æäº§ç”Ÿçš„è¡Œè¯„è®º
                        if java_analysis.get('line_comments'):
                            if file_path not in review_results['line_comments']:
                                review_results['line_comments'][file_path] = {}
                            review_results['line_comments'][file_path].update(
                                java_analysis['line_comments']
                            )
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                if change.get('new_path'):
                    file_ext = change['new_path'].split('.')[-1] if '.' in change['new_path'] else 'no_extension'
                    review_results['summary']['file_types'][file_ext] = \
                        review_results['summary']['file_types'].get(file_ext, 0) + 1

                # ç»Ÿè®¡å˜æ›´è¡Œæ•°
                if change.get('diff'):
                    additions = len(re.findall(r'^\+[^+]', change['diff'], re.MULTILINE))
                    deletions = len(re.findall(r'^-[^-]', change['diff'], re.MULTILINE))
                    review_results['summary']['total_additions'] += additions
                    review_results['summary']['total_deletions'] += deletions
                    
            except Exception as e:
                logger.exception(f"Error analyzing file: {change.get('new_path', 'unknown file')}")
                
        return review_results

    def _analyze_single_file(self, change: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        file_path = change.get('new_path', '')
        file_analysis = {
            'file_path': file_path,
            'change_type': self._determine_change_type(change),
            'issues': [],
            'warnings': [],
            'suggestions': [],
            'line_comments': {}  # æ·»åŠ è¡Œè¯„è®ºæ”¶é›†
        }

        try:
            if change.get('diff'):
                current_line = 0
                
                # åˆ†ædiffè·å–è¡Œå·
                diff_lines = change['diff'].split('\n')
                for line in diff_lines:
                    if line.startswith('@@'):
                        match = re.search(r'\+(\d+)', line)
                        if match:
                            current_line = int(match.group(1)) - 1
                        continue
                    
                    if line.startswith('+'):
                        current_line += 1
                        # åˆ†ææ–°æ·»åŠ çš„ä»£ç è¡Œ
                        line_issues = self._analyze_code_line(line[1:], file_path)
                        if line_issues:
                            file_analysis['line_comments'][current_line] = line_issues
                    
                    elif line.startswith(' '):
                        current_line += 1

        except Exception as e:
            logger.exception(f"Error analyzing file: {file_path}")
            file_analysis['issues'].append(f"æ–‡ä»¶åˆ†æé”™è¯¯: {str(e)}")

        return file_analysis

    def _submit_review_results(self, mr: ProjectMergeRequest, review_results: Dict[str, Any]) -> None:
        """æäº¤è¯„å®¡ç»“æœ"""
        try:
            # 1. æäº¤æ€»ä½“è¯„è®º
            overview_comment = self._format_review_comment(review_results)
            
            # 2. å¦‚æœæœ‰ AI è¯„å®¡ç»“æœï¼Œæ·»åŠ åˆ°è¯„è®ºä¸­
            if 'ai_review' in review_results:
                ai_comment = self.ai_reviewer.format_review_comment(review_results['ai_review'])
                overview_comment = f"{overview_comment}\n\n{ai_comment}"
            
            mr.notes.create({'body': overview_comment})
            logger.info("Successfully submitted overview comment")
            
            # 3. æäº¤è¡Œçº§åˆ«è¯„è®º
            if review_results.get('line_comments'):
                self._submit_line_comments(mr, review_results['line_comments'])
            
            logger.info("Successfully submitted all review comments")
            
        except Exception as e:
            logger.exception("Failed to submit review results")
            raise

    def _submit_line_comments(self, mr: ProjectMergeRequest, line_comments: Dict[str, Dict[int, List[str]]]) -> None:
        """
        æäº¤è¡Œçº§åˆ«è¯„è®º
        
        Args:
            mr: MRå¯¹è±¡
            line_comments: è¡Œè¯„è®ºå­—å…¸ {file_path: {line_number: [comments]}}
        """
        try:
            base_sha = mr.diff_refs['base_sha']
            head_sha = mr.diff_refs['head_sha']
            start_sha = mr.diff_refs.get('start_sha', base_sha)
            
            # æŒ‰æ–‡ä»¶å¤„ç†è¯„è®º
            for file_path, comments in line_comments.items():
                logger.info(f"Creating comments for file: {file_path}")
                
                # æŒ‰è¡Œå¤„ç†è¯„è®º
                for line_num, line_issues in comments.items():
                    try:
                        # æ ¼å¼åŒ–è¯„è®ºå†…å®¹
                        comment_body = self._format_line_comment_body(line_issues)
                        
                        # åˆ›å»ºè¯„è®º
                        position_data = {
                            'base_sha': base_sha,
                            'start_sha': start_sha,
                            'head_sha': head_sha,
                            'position_type': 'text',
                            'new_path': file_path,
                            'new_line': line_num,
                            'old_path': file_path,
                            'old_line': None
                        }
                        
                        mr.discussions.create({
                            'body': comment_body,
                            'position': position_data
                        })
                        
                        logger.debug(f"Created comment for line {line_num} in {file_path}")
                        
                    except Exception as e:
                        logger.error(f"Failed to create comment for line {line_num} in {file_path}: {str(e)}")
                        
        except Exception as e:
            logger.exception("Failed to submit line comments")
            raise

    def _format_line_comment_body(self, issues: List[str]) -> str:
        """
        æ ¼å¼åŒ–è¡Œè¯„è®ºå†…å®¹
        
        Args:
            issues: é—®é¢˜åˆ—è¡¨
            
        Returns:
            æ ¼å¼åŒ–åçš„è¯„è®ºå†…å®¹
        """
        # æŒ‰ç±»å‹å¯¹é—®é¢˜è¿›è¡Œåˆ†ç±»
        categorized_issues = {
            'âŒ ä¸¥é‡é—®é¢˜': [],
            'âš ï¸ è­¦å‘Š': [],
            'ğŸ’¡ å»ºè®®': []
        }
        
        for issue in issues:
            if any(keyword in issue.lower() for keyword in ['error', 'critical', 'severe', 'ä¸¥é‡']):
                categorized_issues['âŒ ä¸¥é‡é—®é¢˜'].append(issue)
            elif any(keyword in issue.lower() for keyword in ['warning', 'caution', 'è­¦å‘Š']):
                categorized_issues['âš ï¸ è­¦å‘Š'].append(issue)
            else:
                categorized_issues['ğŸ’¡ å»ºè®®'].append(issue)
        
        # æ„å»ºè¯„è®ºå†…å®¹
        comment_parts = ['### ä»£ç è¯„å®¡æ„è§']
        
        for category, category_issues in categorized_issues.items():
            if category_issues:
                comment_parts.append(f"\n**{category}:**")
                for issue in category_issues:
                    comment_parts.append(f"- {issue}")
        
        # å¦‚æœæœ‰å»ºè®®çš„ä»£ç ç¤ºä¾‹ï¼Œæ·»åŠ åˆ°è¯„è®ºä¸­
        if any('example' in issue.lower() or 'ç¤ºä¾‹' in issue for issue in issues):
            comment_parts.append("\n**ğŸ’» å‚è€ƒç¤ºä¾‹:**")
            for issue in issues:
                if 'example' in issue.lower() or 'ç¤ºä¾‹' in issue:
                    comment_parts.append("```java\n" + issue.split('example:')[-1].strip() + "\n```")
        
        return "\n".join(comment_parts)

    def _create_batch_comments(self, mr: ProjectMergeRequest, file_path: str, 
                         comments: Dict[int, List[str]], batch_size: int = 5) -> None:
        """
        æ‰¹é‡åˆ›å»ºè¯„è®º
        
        Args:
            mr: MRå¯¹è±¡
            file_path: æ–‡ä»¶è·¯å¾„
            comments: è¯„è®ºå­—å…¸
            batch_size: æ‰¹æ¬¡å¤§å°
        """
        try:
            # è·å–å¿…è¦çš„SHAå€¼
            base_sha = mr.diff_refs['base_sha']
            head_sha = mr.diff_refs['head_sha']
            start_sha = mr.diff_refs.get('start_sha', base_sha)
            
            # å°†è¯„è®ºæŒ‰æ‰¹æ¬¡å¤„ç†
            comment_items = list(comments.items())
            for i in range(0, len(comment_items), batch_size):
                batch = dict(comment_items[i:i + batch_size])
                
                for line_num, issues in batch.items():
                    try:
                        comment_body = self._format_line_comment_body(issues)
                        position_data = {
                            'base_sha': base_sha,
                            'start_sha': start_sha,
                            'head_sha': head_sha,
                            'position_type': 'text',
                            'new_path': file_path,
                            'new_line': line_num,
                            'old_path': file_path,
                            'old_line': None
                        }
                        
                        mr.discussions.create({
                            'body': comment_body,
                            'position': position_data
                        })
                        
                        logger.debug(f"Created comment for line {line_num} in {file_path}")
                        
                    except Exception as e:
                        logger.error(f"Failed to create comment for line {line_num}: {str(e)}")
                
                # æ·»åŠ å»¶è¿Ÿä»¥é¿å…è§¦å‘APIé™åˆ¶
                sleep(1)
                
        except Exception as e:
            logger.exception(f"Failed to create batch comments for {file_path}")
            raise

   


def main():
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    # è·å–é…ç½®
    gitlab_token = os.getenv('GITLAB_TOKEN')
    gitlab_url = os.getenv('GITLAB_URL', 'https://gitlab.com')
    mr_url = os.getenv('MR_URL','https://gitlab.com/your-group/your-project/-/merge_requests/1')
    
    if not all([gitlab_token, mr_url]):
        logger.error("Missing required environment variables")
        return
    
    try:
        # åˆå§‹åŒ–è§£æå™¨å¹¶æ‰§è¡Œè¯„å®¡
        parser = GitLabMRParser(gitlab_token=gitlab_token, gitlab_url=gitlab_url)
        results = parser.review_mr(mr_url)
        
        # è¾“å‡ºç»“æœ
        logger.info("Review completed successfully")
        logger.debug(f"Review results: {json.dumps(results, indent=2)}")
        
    except Exception as e:
        logger.exception("Error during code review")
